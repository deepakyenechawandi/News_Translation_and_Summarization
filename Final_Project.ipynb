{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer, pipeline, MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import math\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "# Install necessary libraries if not already installed\n",
        "!pip install -q transformers gradio pytesseract\n",
        "!sudo apt update -q\n",
        "!sudo apt install -q tesseract-ocr\n",
        "\n",
        "# --- Model Loading ---\n",
        "# Load translation model and tokenizer\n",
        "translator_model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "try:\n",
        "    translator_tokenizer = MBart50TokenizerFast.from_pretrained(translator_model_name)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading MBart tokenizer: {e}\")\n",
        "    # Fallback or exit if tokenizer can't be loaded\n",
        "\n",
        "try:\n",
        "    translator_model = MBartForConditionalGeneration.from_pretrained(translator_model_name)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading MBart model: {e}\")\n",
        "    # Fallback or exit if model can't be loaded\n",
        "\n",
        "# Load summarization pipeline\n",
        "summarizer_model_name = \"t5-base\"\n",
        "try:\n",
        "    summarizer = pipeline(\"summarization\", model=summarizer_model_name, tokenizer=summarizer_model_name)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading summarization model {summarizer_model_name}: {e}\")\n",
        "    summarizer = None # Handle case where summarizer fails to load\n",
        "\n",
        "\n",
        "# --- OCR Function ---\n",
        "def perform_ocr_on_image(image):\n",
        "    \"\"\"Performs OCR on a PIL Image and returns the extracted text.\"\"\"\n",
        "    if image is None:\n",
        "        return \"\"\n",
        "    try:\n",
        "        text = pytesseract.image_to_string(image)\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error during OCR: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "# --- Translation Function ---\n",
        "def translate_text(text, source_language_code, target_language_code, translator_tokenizer, translator_model):\n",
        "    \"\"\"Translates text to the target language using MBart model.\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    try:\n",
        "        translator_tokenizer.src_lang = source_language_code\n",
        "        encoded = translator_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)\n",
        "\n",
        "        generated_tokens = translator_model.generate(\n",
        "            **encoded,\n",
        "            forced_bos_token_id=translator_tokenizer.lang_code_to_id[target_language_code],\n",
        "            max_length=512,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        translated_text = translator_tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
        "        return translated_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error during translation: {e}\")\n",
        "        return f\"Translation failed: {e}\"\n",
        "\n",
        "\n",
        "# --- Summarization Function ---\n",
        "def summarize_text(text, summarizer):\n",
        "    \"\"\"Summarizes the input text.\"\"\"\n",
        "    if not text or summarizer is None:\n",
        "        return \"Summarization model not loaded or no text to summarize.\"\n",
        "    try:\n",
        "        # Clean up unwanted characters that might appear after translation\n",
        "        cleaned_text = text.replace('!', '').replace(',', '').replace('.', '').replace(';', '').replace(':', '')\n",
        "        cleaned_text = cleaned_text.replace('(', '').replace(')', '').replace('[', '').replace(']', '')\n",
        "        cleaned_text = cleaned_text.replace('*', '').replace(\"'\", '').replace('\"', '')\n",
        "        cleaned_text = cleaned_text.strip() # Remove leading/trailing whitespace\n",
        "\n",
        "        if not cleaned_text:\n",
        "             return \"Translated text is empty or only contains punctuation after cleaning.\"\n",
        "\n",
        "        max_summarizer_input_length = 1024\n",
        "        input_text_for_summarizer = cleaned_text[:max_summarizer_input_length]\n",
        "\n",
        "        # You can adjust parameters like max_length and min_length for summarization\n",
        "        summary = summarizer(input_text_for_summarizer, max_length=200, min_length=30, do_sample=False, truncation=True)\n",
        "        return summary[0]['summary_text']\n",
        "    except Exception as e:\n",
        "        print(f\"Error during summarization: {e}\")\n",
        "        return f\"Summarization failed: {e}\"\n",
        "\n",
        "# Update the call to summarize_text in the translate_and_summarize function\n",
        "def translate_and_summarize(article_text, article_image, source_language, target_language, translator_tokenizer, translator_model, summarizer):\n",
        "    \"\"\"Translates and then summarizes the article text, optionally from an image.\"\"\"\n",
        "    processed_text = \"\"\n",
        "    if article_text:\n",
        "        processed_text = article_text\n",
        "    elif article_image:\n",
        "        processed_text = perform_ocr_on_image(article_image)\n",
        "        if not processed_text:\n",
        "            print(\"OCR failed to extract text from image.\")\n",
        "            return \"Could not extract text from the image.\", \"Summarization requires extracted text.\"\n",
        "    else:\n",
        "        return \"Please provide article text or an image.\", \"Summarization requires input.\"\n",
        "\n",
        "    # Map dropdown language names to MBart language codes\n",
        "    lang_codes = {\n",
        "        \"English\": \"en_XX\",\n",
        "        \"French\": \"fr_XX\",\n",
        "        \"Spanish\": \"es_XX\",\n",
        "        \"German\": \"de_DE\",\n",
        "        \"Italian\": \"it_IT\",\n",
        "        \"Russian\": \"ru_RU\",\n",
        "        \"Dutch\": \"nl_XX\"\n",
        "    }\n",
        "\n",
        "    source_lang_code = lang_codes.get(source_language)\n",
        "    target_lang_code = lang_codes.get(target_language)\n",
        "\n",
        "    if not source_lang_code or not target_lang_code:\n",
        "        print(f\"Invalid source ({source_language}) or target ({target_language}) language selected.\")\n",
        "        return \"Invalid source or target language selected.\", \"Cannot summarize if translation failed.\"\n",
        "\n",
        "    print(f\"Processing text from {source_language} ({source_lang_code}) to {target_language} ({target_lang_code})\")\n",
        "    print(f\"Original Text (first 100 chars): {processed_text[:100]}...\")\n",
        "\n",
        "    translated_article = translate_text(processed_text, source_lang_code, target_lang_code, translator_tokenizer, translator_model)\n",
        "\n",
        "    print(\"Translated Text for Summarization (first 100 chars):\")\n",
        "    print(translated_article[:100])\n",
        "    if \"Translation failed\" in translated_article:\n",
        "        return translated_article, \"Cannot summarize due to translation error.\"\n",
        "\n",
        "    # Call summarize_text with the translated article and summarizer\n",
        "    summarized_article = summarize_text(translated_article, summarizer)\n",
        "    print(\"Summarized Text (first 100 chars):\")\n",
        "    print(summarized_article[:100])\n",
        "    if \"Summarization failed\" in summarized_article or \"Summarization model not loaded\" in summarized_article:\n",
        "        return translated_article, summarized_article\n",
        "\n",
        "    return translated_article, summarized_article\n",
        "\n",
        "# The rest of the code remains the same, just update the summarize_text function and the call within translate_and_summarize\n",
        "\n",
        "# --- User Interface using Gradio ---\n",
        "\n",
        "# Define input components\n",
        "article_input = gr.Textbox(label=\"Enter Article Text\")\n",
        "article_image_input = gr.Image(type=\"pil\", label=\"Upload Article Image (OCR Enabled)\")\n",
        "language_choices = [\"English\", \"French\", \"Spanish\", \"German\", \"Italian\", \"Russian\", \"Dutch\"]\n",
        "source_lang_input = gr.Dropdown(\n",
        "    label=\"Source Language (Ensure model supports)\",\n",
        "    choices=language_choices,\n",
        "    value=\"English\"\n",
        ")\n",
        "target_lang_input = gr.Dropdown(\n",
        "    label=\"Target Language (Ensure model supports)\",\n",
        "    choices=language_choices,\n",
        "    value=\"English\"\n",
        ")\n",
        "\n",
        "# Define output components\n",
        "translated_output = gr.Textbox(label=\"Translated Article\")\n",
        "summarized_output = gr.Textbox(label=\"Summarized Article\")\n",
        "\n",
        "# Create the Gradio interface, passing models and tokenizers as arguments\n",
        "iface = gr.Interface(\n",
        "    fn=lambda text, img, src_lang, tgt_lang: translate_and_summarize(\n",
        "        text, img, src_lang, tgt_lang, translator_tokenizer, translator_model, summarizer\n",
        "    ),\n",
        "    inputs=[article_input, article_image_input, source_lang_input, target_lang_input],\n",
        "    outputs=[translated_output, summarized_output],\n",
        "    title=\"News Translation and Summarization\",\n",
        "    description=\"Enter article text or upload an image for translation and summarization. Supports multiple languages.\",\n",
        "    analytics_enabled=False\n",
        ")\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "if __name__ == \"__main__\":\n",
        "    drive.mount('/content/drive', force_remount=True) # Mount drive\n",
        "    !pwd # Print current directory\n",
        "    iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aWtJIN3NWThB",
        "outputId": "55cbb12f-cbf6-4681-b7dc-36b1a0fcb950"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "35 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d164cda647f4b196ac.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d164cda647f4b196ac.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}